{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: ICD-AIS conversion using Deep Learning utilizing ICD10\n",
    "\n",
    "This script translates checks the translations against the actual AIS codes that were recorded in NTDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translations\n",
    "aaam_ais_file = \"../Results/Translations/ais_aaam_map.csv\"\n",
    "icdpic_ais_file = \"../Results/Translations/test_ais_icdpic.csv\"\n",
    "nmt_ais_file = \"../Results/Translations/nmt_ais.csv\"\n",
    "\n",
    "# observed ais codes\n",
    "test_ais_file = \"../Results/Translations/ais_obs.csv\"\n",
    "\n",
    "# AIS codes\n",
    "ais_codes_file = \"../Tools/AIS08_codes.csv\"\n",
    "\n",
    "# output for results\n",
    "results_file = \"../Results/ais_results.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load result files\n",
    "aaam = pd.read_csv(aaam_ais_file)\n",
    "icdpic = pd.read_csv(icdpic_ais_file)\n",
    "nmt = pd.read_csv(nmt_ais_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test observations\n",
    "test_obs = pd.read_csv(test_ais_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to match AIS codes from two list\n",
    "This function will return the best estimate for matching two lists of AIS codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_ais(ais1, ais2):\n",
    "    '''\n",
    "    This function matches AIS codes from two lists with proximation.  The overarching concept\n",
    "    is to match codes based on 1) exact matches, 2) same body region-same severity, \n",
    "    3) same body region-different severity, 4) different body region-same severity, \n",
    "    5) remaining codes are paired in decreasing severity, 6) unmatched codes are then added.\n",
    "    \n",
    "    Parameters:\n",
    "        ais1 - list of AIS codes\n",
    "        ais2 - list of AIS codes\n",
    "    Returns:\n",
    "        Pandas dataframe with matched codes\n",
    "    '''\n",
    "    \n",
    "    # df for matches\n",
    "    matches = pd.DataFrame(columns={'codes1','code2'})\n",
    "    \n",
    "    # df for data\n",
    "    df1 = pd.DataFrame({'ais_code':ais1, 'curr_prec':ais1}).sort_values('ais_code')\n",
    "    df2 = pd.DataFrame({'ais_code':ais2, 'curr_prec':ais2}).sort_values('ais_code')\n",
    "\n",
    "    # determine body region\n",
    "    df1['region'] = np.floor(df1.ais_code/100000)\n",
    "    df2['region'] = np.floor(df2.ais_code/100000)\n",
    "    \n",
    "    # determine severity\n",
    "    df1['severity'] = np.round(df1.curr_prec%1 * 10)\n",
    "    df2['severity'] = np.round(df2.curr_prec%1 * 10)\n",
    "\n",
    "    # move severity to the 2nd MSD\n",
    "    df1['curr_prec'] = np.floor(df1.region * 1000000 + df1.severity * 100000 + df1.ais_code%100000)\n",
    "    df2['curr_prec'] = np.floor(df2.region * 1000000 + df2.severity * 100000 + df2.ais_code%100000)    \n",
    "    \n",
    "    # matching steps #1-3, loop through all digits\n",
    "    for digit in range(0,7):\n",
    "\n",
    "        # loop through ais1 codes\n",
    "        for i in range(0,len(df1)):\n",
    "\n",
    "            # loop through ais2 codes\n",
    "            for j in range(0,len(df2)):\n",
    "\n",
    "                # check for match\n",
    "                if df1.curr_prec[i] == df2.curr_prec[j]:\n",
    "\n",
    "                    # match found, add to match list\n",
    "                    matches = matches.append({'code1':df1.ais_code[i], 'code2':df2.ais_code[j]}, ignore_index=True)\n",
    "\n",
    "                    # remove rows with matched codes from dfs\n",
    "                    df1 = df1.drop(index=i, axis=1)\n",
    "                    df2 = df2.drop(index=j, axis=1).reset_index(drop=True)\n",
    "\n",
    "                    # stop searching for code\n",
    "                    break\n",
    "\n",
    "        # decrease precision, on first loop this removes severity\n",
    "        df1['curr_prec'] = np.floor(df1.curr_prec/10)\n",
    "        df2['curr_prec'] = np.floor(df2.curr_prec/10)\n",
    "\n",
    "        # reset index for list1\n",
    "        df1 = df1.reset_index(drop=True) \n",
    "\n",
    "    # matching step #4 - find same severity in different body regions    \n",
    "        \n",
    "    # assign severity to current precision\n",
    "    df1['curr_prec'] = df1.severity\n",
    "    df2['curr_prec'] = df2.severity\n",
    "    \n",
    "    # sort based on codes\n",
    "    df1 = df1.sort_values('ais_code').reset_index(drop=True)\n",
    "    df2 = df2.sort_values('ais_code').reset_index(drop=True)\n",
    "    \n",
    "    #loop through all unmatched codes in list 1\n",
    "    for i in range(0,len(df1)):\n",
    "        \n",
    "        # loop through unmatched codes in list 2\n",
    "        for j in range(0,len(df2)):\n",
    "                \n",
    "            # check for match\n",
    "            if df1.curr_prec[i] == df2.curr_prec[j]:\n",
    "\n",
    "                # match found, add to match list\n",
    "                matches = matches.append({'code1':df1.ais_code[i], 'code2':df2.ais_code[j]}, ignore_index=True)\n",
    "\n",
    "                # remove rows with matched codes from dfs\n",
    "                df1 = df1.drop(index=i, axis=1)\n",
    "                df2 = df2.drop(index=j, axis=1).reset_index(drop=True)\n",
    "\n",
    "                # stop searching for code\n",
    "                break\n",
    "                \n",
    "    # matching step #5-6, sequentially assign unmatched codes from based on decreasing AIS severity\n",
    "\n",
    "    # arrange in decreasing severity\n",
    "    df1 = df1.sort_values('curr_prec', ascending=False).reset_index(drop=True)\n",
    "    df2 = df2.sort_values('curr_prec', ascending=False).reset_index(drop=True)\n",
    "  \n",
    "    #loop through all unmatched codes in list 1\n",
    "    for i in range(0,len(df1)):\n",
    "\n",
    "        # check if list 2 still has any numbers\n",
    "        if len(df2) > 0:\n",
    "\n",
    "            # add to match list\n",
    "            matches = matches.append({'code1':df1.ais_code[i], 'code2':df2.ais_code[0]}, ignore_index=True)\n",
    "\n",
    "            # remove rows with matched codes from df\n",
    "            df2 = df2.drop(index=0, axis=1).reset_index(drop=True)\n",
    "\n",
    "        # else no more codes in list 2\n",
    "        else:\n",
    "\n",
    "            # add to match list\n",
    "            matches = matches.append({'code1':df1.ais_code[i], 'code2':None}, ignore_index=True)\n",
    "\n",
    "        # remove code from list 1\n",
    "        df1 = df1.drop(index=i, axis=1)\n",
    "\n",
    "    # assign unmatched to any remaining codes list 2\n",
    "    for j in range(0,len(df2)):\n",
    "\n",
    "        # add to match list\n",
    "        matches = matches.append({'code1':None, 'code2':df2.ais_code[j]}, ignore_index=True)\n",
    "        \n",
    "    # remove values that are undefined\n",
    "    matches['code1'] = matches.code1.apply(lambda x: None if x<=0 else x)\n",
    "    matches['code2'] = matches.code2.apply(lambda x: None if x<=0 else x)\n",
    "\n",
    "    # arrange by decrease AIS severity\n",
    "    matches['severity1'] = matches.code1%1\n",
    "    matches = matches.sort_values('code1').sort_values('severity1',ascending=False)[['code1','code2']].reset_index(drop=True)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate ISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ISS(codes_list, region_list, NISS=False):\n",
    "    '''\n",
    "    This function accepts a list of AIS codes and returns the ISS.  This is based\n",
    "    on the six body regions method.\n",
    "    \n",
    "    Parameters:\n",
    "        ais_codes - list of AIS codes\n",
    "        NISS - True if the new injury severity score method should be used\n",
    "        \n",
    "    Returns:\n",
    "        ISS or NISS\n",
    "    '''\n",
    "    \n",
    "    # make dataframe from lists\n",
    "    codes_df = pd.DataFrame({'code':codes_list, 'region':region_list}).fillna(0)\n",
    "    \n",
    "    #print(codes_df)\n",
    "    \n",
    "    # get severity and severity squared\n",
    "    codes_df['severity'] = ((codes_df.code*10)%10).astype(int)\n",
    "    codes_df['severity_sq'] = np.square(codes_df.severity)\n",
    "       \n",
    "    # check if any severity greater than 7, then unknown\n",
    "    if (codes_df.severity>=7).any():\n",
    "        # IS is unknown\n",
    "        IS = np.nan\n",
    "\n",
    "    # else check if any severity is 6, then automatic 75\n",
    "    elif (codes_df.severity==6).any():\n",
    "        # IS is max (75)\n",
    "        IS = 75\n",
    "        \n",
    "    # calculate injury severity\n",
    "    else:\n",
    "        # check if using NISS, highest severity in any region\n",
    "        if NISS:\n",
    "            # get 3 highest severity codes\n",
    "            codes_df = codes_df.sort_values('severity', ascending=False).reset_index(drop=True).head(3)\n",
    "\n",
    "            # calculate injury severity\n",
    "            IS = sum(codes_df.severity_sq)\n",
    "            \n",
    "        # else using ISS, highest severity in different body regions\n",
    "        else:\n",
    "            # get highest severity codes in different body regions\n",
    "            codes_df = codes_df.sort_values('severity', ascending=False).groupby('region').head(1).reset_index(drop=True)\n",
    "            \n",
    "            # get 3 highest severity codes\n",
    "            codes_df = codes_df.sort_values('severity', ascending=False).reset_index(drop=True).head(3)\n",
    "            \n",
    "            # calculate injury severity\n",
    "            IS = sum(codes_df.severity_sq)\n",
    "        \n",
    "    return IS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to evaluate matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_matches(codes_df, region='chapter'):\n",
    "    '''\n",
    "    This function determines the level of match  between paired\n",
    "    lists of AIS codes.  \n",
    "\n",
    "    Parameter:\n",
    "        codes_df - dataframe with matched list of AIS codes, two columns of AIS codes\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe with match level totals for injury lists.  The levels are:\n",
    "            exact - number of exact matches\n",
    "            same_reg_same_sev - same body region, same severity, but not exact match\n",
    "            same_reg_diff_sev - same body region, different severity \n",
    "            diff_reg_same_sev - same body region, different severity \n",
    "            diff_reg_diff_sev - different body region, different severity, but matched\n",
    "            unmatched_obs - number of unmatched observed codes\n",
    "            unmatched_pred - number of unmatched predicted codes\n",
    "            region - type of region to use for calculation, options:\n",
    "                'chapter' = AIS manual chapter [1st digit of code]\n",
    "                'iss' = regions used to calculate ISS\n",
    "    '''\n",
    "    \n",
    "    # make sure column names are correct\n",
    "    codes_df = codes_df.rename(columns={codes_df.columns[0]:'obs',codes_df.columns[1]:'pred'})\n",
    "    \n",
    "    # fill in NaN with 0\n",
    "    codes_df = codes_df.fillna(0)\n",
    "    \n",
    "    # add region to codes\n",
    "    if region == 'chapter':\n",
    "        # if using chapter for region get MSD for region\n",
    "        codes_df['reg_obs'] = np.floor(codes_df.obs/100000).astype(int)\n",
    "        codes_df['reg_pred'] = np.floor(codes_df.pred/100000).astype(int)\n",
    "        \n",
    "    else:\n",
    "        # if using ISS region, get 2nd MSD for region\n",
    "        codes_df['reg_obs'] = np.floor((codes_df.obs/10000)%10).astype(int)\n",
    "        codes_df['reg_pred'] = np.floor((codes_df.pred/10000)%10).astype(int)        \n",
    "    \n",
    "    # get severity and severity squared\n",
    "    codes_df['sev_obs'] = ((codes_df.obs*10)%10).astype(int)\n",
    "    codes_df['sev_pred'] = ((codes_df.pred*10)%10).astype(int)\n",
    "    \n",
    "    # evaluate for exact matches\n",
    "    codes_df['exact'] = codes_df.apply(lambda x: 1 if x['obs']==x['pred'] else 0, axis=1)\n",
    "    \n",
    "    # evaluate for same region, same severity, but not exact match\n",
    "    codes_df['same_reg_same_sev'] = codes_df.apply(lambda x: 1 if ((x['exact']==0) & \\\n",
    "                                                                   (x['reg_obs']==x['reg_pred']) & \\\n",
    "                                                                   (x['sev_obs']==x['sev_pred'])) else 0, axis=1)\n",
    "    \n",
    "    # evaluate for same region, different severity\n",
    "    codes_df['same_reg_diff_sev'] = codes_df.apply(lambda x: 1 if ((x['reg_obs']==x['reg_pred']) & \\\n",
    "                                                                   (x['sev_obs']!=x['sev_pred'])) else 0, axis=1)\n",
    "    \n",
    "    # evaluate for different region, same severity\n",
    "    codes_df['diff_reg_same_sev'] = codes_df.apply(lambda x: 1 if ((x['reg_obs']!=x['reg_pred']) & \\\n",
    "                                                                   (x['sev_obs']==x['sev_pred'])) else 0, axis=1)\n",
    "    \n",
    "    # evaluate for different region, different severity, but not completely unmatched\n",
    "    codes_df['diff_reg_diff_sev'] = codes_df.apply(lambda x: 1 if ((x['reg_obs']!=x['reg_pred']) & \\\n",
    "                                                                   (x['sev_obs']!=x['sev_pred']) & \\\n",
    "                                                                   (x['obs']!=0) & (x['pred']!=0)) else 0, axis=1)\n",
    "    \n",
    "    # evaluate for unmatched codes\n",
    "    codes_df['unmatched_obs'] = codes_df.apply(lambda x: 1 if x['pred']==0 else 0, axis=1)    \n",
    "    codes_df['unmatched_pred'] = codes_df.apply(lambda x: 1 if x['obs']==0 else 0, axis=1) \n",
    "        \n",
    "    return codes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get AIS code match statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_iss_region_df(df):\n",
    "    \n",
    "    return df.aiscode - (np.floor(df.aiscode/10000)%10)*10000 + df.region*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_matches_df(obs, pred, convert_region_obs, convert_region_pred, region='chapter', col_suff=''):\n",
    "    '''\n",
    "    This function takes a two dataframes with injuries list.  It matches injuries \n",
    "    based on the patient key and then evaluates the quality of the matches.\n",
    "\n",
    "    Parameter:\n",
    "        obs - dataframe with list of observed AIS codes (must contain 'inc_key' and 'aiscode')\n",
    "        pred - dataframe with list of predicted AIS codes (must contain 'inc_key' and 'aiscode')\n",
    "        convert_region_obs - convert the 2nd MSD to the region for observations\n",
    "        convert_region_obs - convert the 2nd MSD to the region for predictins\n",
    "        region - 'chapter' for AIS manual chapter regions, 'iss' for ISS regions\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe with a summary of the match level totals for all patients.  The levels are:\n",
    "            exact - number of exact matches\n",
    "            same_reg_same_sev - same body region, same severity, but not exact match\n",
    "            same_reg_diff_sev - same body region, different severity \n",
    "            diff_reg_same_sev - same body region, different severity \n",
    "            diff_reg_diff_sev - different body region, different severity, but matched\n",
    "            unmatched_obs - number of unmatched observed codes\n",
    "            unmatched_pred - number of unmatched predicted codes\n",
    "            convert_region_obs - True if the 2nd MSD should be replaced with the region\n",
    "            convert_region_pred - True if the 2nd MSD should be replaced with the region\n",
    "            region - type of region to use for calculation, options:\n",
    "                'chapter' = AIS manual chapter [1st digit of code]\n",
    "                'iss' = regions used to calculate ISS\n",
    "            col_suff - suffix for columns with results\n",
    "    '''\n",
    "    \n",
    "    # get all keys from prediction and observations\n",
    "    keys = np.unique(np.concatenate([test_obs['inc_key'], aaam['inc_key']]))\n",
    "    \n",
    "    # loop through all keys\n",
    "    for i,key in enumerate(keys):\n",
    "        \n",
    "        #print(i)\n",
    "        \n",
    "        # get aiscodes from observations\n",
    "        if convert_region_obs==True:\n",
    "            # obtain aiscodes and add region to 2nd MSB\n",
    "            obs_codes = add_iss_region_df(obs[obs.inc_key==key].reset_index(drop=True))\n",
    "        \n",
    "        else:\n",
    "            # obtain aiscodes without modification\n",
    "            obs_codes = obs[obs.inc_key==key].reset_index(drop=True).aiscode\n",
    "            \n",
    "        # get aiscodes from predictions\n",
    "        if convert_region_pred==True:\n",
    "            # obtain aiscodes and add region to 2nd MSB\n",
    "            pred_codes = add_iss_region_df(pred[pred.inc_key==key].reset_index(drop=True))\n",
    "\n",
    "        else:\n",
    "            # obtain aiscodes without modification\n",
    "            pred_codes = pred[pred.inc_key==key].reset_index(drop=True).aiscode\n",
    "        \n",
    "        # match observed and predicted code\n",
    "        matched_list = match_ais(obs_codes, pred_codes)\n",
    "        \n",
    "        # evaluate level of matches\n",
    "        match_results = eval_matches(matched_list, region)\n",
    "        \n",
    "        # sum results and select for necessary columns\n",
    "        results_sum = pd.DataFrame(match_results.sum(axis=0)).T[['exact','same_reg_same_sev',\n",
    "                                                                 'same_reg_diff_sev','diff_reg_same_sev',\n",
    "                                                                 'diff_reg_diff_sev','unmatched_obs',\n",
    "                                                                 'unmatched_pred']]\n",
    "        # add key\n",
    "        results_sum['inc_key'] = key\n",
    "                \n",
    "        # store in dataframe\n",
    "        if i==0:\n",
    "            results = results_sum.copy()\n",
    "        else:\n",
    "            results = results.append(results_sum).reset_index(drop=True)\n",
    "                   \n",
    "        #if i>=100:\n",
    "        #    break\n",
    "            \n",
    "        if (i%1000)==0:\n",
    "            print(i)\n",
    "    \n",
    "    # add suffix for column names, except inc_key\n",
    "    results = results.add_suffix(col_suff).rename(columns={'inc_key'+col_suff: 'inc_key'})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to determine ISS from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_iss(df):\n",
    "    '''\n",
    "    Calculates Injury Severity Score from a datafame.  The dataframe\n",
    "    should have one injury per row and should have the following columns:\n",
    "        inc_key - unique patient key\n",
    "        aiscode - fully AIS code\n",
    "        region - ISS region of injury\n",
    "    \n",
    "    Paramaters:\n",
    "    df - datafame\n",
    "    \n",
    "    Returns:\n",
    "    ISS\n",
    "    '''\n",
    "    \n",
    "    # list for ISS results\n",
    "    iss=[]\n",
    "    \n",
    "    # dataframe for pt data\n",
    "    df_pt = df[['inc_key']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # get lists of observe ais codes\n",
    "    df_pt['ais']=df.groupby('inc_key')['aiscode'].apply(list).values\n",
    "    df_pt['region']=df.groupby('inc_key')['region'].apply(list).values\n",
    "    \n",
    "    # iterrate through each row\n",
    "    for i,row in df_pt.iterrows():\n",
    "        iss.append(calc_ISS(row.ais, row.region))\n",
    "        \n",
    "    return iss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_mais(df):\n",
    "    '''\n",
    "    Calculates Maximum Abbreviated Injury Score from a datafame.  The dataframe\n",
    "    should have one injury per row and should have the following columns:\n",
    "        inc_key - unique patient key\n",
    "        severity - AIS severity as an integer.\n",
    "    \n",
    "    Paramaters:\n",
    "    df - datafame\n",
    "    \n",
    "    Returns:\n",
    "    MAIS\n",
    "    '''\n",
    "    \n",
    "    # group by key and get max severity\n",
    "    return df.groupby('inc_key')['severity'].max().values   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe for results\n",
    "res = test_obs[['inc_key']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(icdpic.inc_key.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc ISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 127 ms, total: 1min 40s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# iss for observations, nmt, AAAM map, and ICDPICR\n",
    "res['iss_obs'] = df_iss(test_obs)\n",
    "res['iss_nmt'] = df_iss(nmt)\n",
    "res['iss_aaam'] = df_iss(aaam)\n",
    "res['iss_icdpic'] = df_iss(icdpic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if prediction match observations exact iss\n",
    "res['iss_correct_nmt'] = np.where(res['iss_obs']==res['iss_nmt'],1,0)\n",
    "res['iss_correct_aaam'] = np.where(res['iss_obs']==res['iss_aaam'],1,0)\n",
    "res['iss_correct_icdpic'] = np.where(res['iss_obs']==res['iss_icdpic'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inc_key               1.900334e+11\n",
       "iss_obs               8.869521e+00\n",
       "iss_nmt               8.590475e+00\n",
       "iss_aaam              7.893000e+00\n",
       "iss_icdpic            6.817600e+00\n",
       "iss_correct_nmt       7.779000e-01\n",
       "iss_correct_aaam      6.894000e-01\n",
       "iss_correct_icdpic    1.772000e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc ISS>=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iss16 (iss): \n",
    "    return 1 if iss >=16 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate columns for iss>=16\n",
    "res['iss16_obs'] = res.iss_obs.apply(iss16)\n",
    "res['iss16_nmt'] = res.iss_nmt.apply(iss16)\n",
    "res['iss16_aaam'] = res.iss_aaam.apply(iss16)\n",
    "res['iss16_icdpic'] = res.iss_icdpic.apply(iss16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if prediction match observations iss>=16\n",
    "res['iss16_correct_nmt'] = np.where(res['iss16_obs']==res['iss16_nmt'],1,0)\n",
    "res['iss16_correct_aaam'] = np.where(res['iss16_obs']==res['iss16_aaam'],1,0)\n",
    "res['iss16_correct_icdpic'] = np.where(res['iss16_obs']==res['iss16_icdpic'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iss16_correct_nmt       0.9368\n",
       "iss16_correct_aaam      0.9132\n",
       "iss16_correct_icdpic    0.8732\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.filter(regex='iss16_correct').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc MAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['mais_obs'] = df_mais(test_obs)\n",
    "res['mais_nmt'] = df_mais(nmt)\n",
    "res['mais_aaam'] = df_mais(aaam)\n",
    "res['mais_icdpic'] = df_mais(icdpic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mais_obs       2.59862\n",
       "mais_nmt       2.58630\n",
       "mais_aaam      2.27750\n",
       "mais_icdpic    2.03050\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.filter(regex='mais').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc MAIS >=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mais3 (mais): \n",
    "    return 1 if mais >=3 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate columns for mais>=3\n",
    "res['mais3_obs'] = res.mais_obs.apply(mais3)\n",
    "res['mais3_nmt'] = res.mais_nmt.apply(mais3)\n",
    "res['mais3_aaam'] = res.mais_aaam.apply(mais3)\n",
    "res['mais3_icdpic'] = res.mais_icdpic.apply(mais3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if prediction match observations mais>=3\n",
    "res['mais3_correct_nmt'] = np.where(res['mais3_obs']==res['mais3_nmt'],1,0)\n",
    "res['mais3_correct_aaam'] = np.where(res['mais3_obs']==res['mais3_aaam'],1,0)\n",
    "res['mais3_correct_icdpic'] = np.where(res['mais3_obs']==res['mais3_icdpic'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mais3_obs               0.3296\n",
       "mais3_nmt               0.2990\n",
       "mais3_aaam              0.3800\n",
       "mais3_icdpic            0.3162\n",
       "mais3_correct_nmt       0.9126\n",
       "mais3_correct_aaam      0.8450\n",
       "mais3_correct_icdpic    0.6880\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.filter(regex='mais3').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc MAIS >=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mais2 (mais): \n",
    "    return 1 if mais >=2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate columns for mais>=3\n",
    "res['mais2_obs'] = res.mais_obs.apply(mais2)\n",
    "res['mais2_nmt'] = res.mais_nmt.apply(mais2)\n",
    "res['mais2_aaam'] = res.mais_aaam.apply(mais2)\n",
    "res['mais2_icdpic'] = res.mais_icdpic.apply(mais2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if prediction match observations mais>=3\n",
    "res['mais2_correct_nmt'] = np.where(res['mais2_obs']==res['mais2_nmt'],1,0)\n",
    "res['mais2_correct_aaam'] = np.where(res['mais2_obs']==res['mais2_aaam'],1,0)\n",
    "res['mais2_correct_icdpic'] = np.where(res['mais2_obs']==res['mais2_icdpic'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mais2_obs               0.6154\n",
       "mais2_nmt               0.6102\n",
       "mais2_aaam              0.8277\n",
       "mais2_icdpic            0.5601\n",
       "mais2_correct_nmt       0.9564\n",
       "mais2_correct_aaam      0.7481\n",
       "mais2_correct_icdpic    0.7333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.filter(regex='mais2').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc match quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "CPU times: user 5min 12s, sys: 482 ms, total: 5min 12s\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get match quality\n",
    "match_nmt = eval_matches_df(test_obs, nmt, convert_region_obs=True, convert_region_pred=True, region='iss', col_suff='_nmt')\n",
    "\n",
    "# add to results\n",
    "res = res.merge(match_nmt, on='inc_key', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "CPU times: user 5min 14s, sys: 660 ms, total: 5min 15s\n",
      "Wall time: 5min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get match quality\n",
    "match_aaam = eval_matches_df(test_obs, aaam, convert_region_obs=True, convert_region_pred=False, region='iss', col_suff='_aaam')\n",
    "\n",
    "# add to results\n",
    "res = res.merge(match_aaam, on='inc_key', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "CPU times: user 5min 21s, sys: 226 ms, total: 5min 21s\n",
      "Wall time: 5min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get match quality\n",
    "match_icdpic = eval_matches_df(test_obs, icdpic, convert_region_obs=True, convert_region_pred=False, region='iss', col_suff='_icdpic')\n",
    "\n",
    "# add to results\n",
    "res = res.merge(match_icdpic, on='inc_key', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inc_key                       0\n",
       "iss_obs                     236\n",
       "iss_nmt                     257\n",
       "iss_aaam                      0\n",
       "iss_icdpic                    0\n",
       "iss_correct_nmt               0\n",
       "iss_correct_aaam              0\n",
       "iss_correct_icdpic            0\n",
       "iss16_obs                     0\n",
       "iss16_nmt                     0\n",
       "iss16_aaam                    0\n",
       "iss16_icdpic                  0\n",
       "iss16_correct_nmt             0\n",
       "iss16_correct_aaam            0\n",
       "iss16_correct_icdpic          0\n",
       "mais_obs                      2\n",
       "mais_nmt                      0\n",
       "mais_aaam                     0\n",
       "mais_icdpic                   0\n",
       "mais3_obs                     0\n",
       "mais3_nmt                     0\n",
       "mais3_aaam                    0\n",
       "mais3_icdpic                  0\n",
       "mais3_correct_nmt             0\n",
       "mais3_correct_aaam            0\n",
       "mais3_correct_icdpic          0\n",
       "mais2_obs                     0\n",
       "mais2_nmt                     0\n",
       "mais2_aaam                    0\n",
       "mais2_icdpic                  0\n",
       "mais2_correct_nmt             0\n",
       "mais2_correct_aaam            0\n",
       "mais2_correct_icdpic          0\n",
       "exact_nmt                     0\n",
       "same_reg_same_sev_nmt         0\n",
       "same_reg_diff_sev_nmt         0\n",
       "diff_reg_same_sev_nmt         0\n",
       "diff_reg_diff_sev_nmt         0\n",
       "unmatched_obs_nmt             0\n",
       "unmatched_pred_nmt            0\n",
       "exact_aaam                    0\n",
       "same_reg_same_sev_aaam        0\n",
       "same_reg_diff_sev_aaam        0\n",
       "diff_reg_same_sev_aaam        0\n",
       "diff_reg_diff_sev_aaam        0\n",
       "unmatched_obs_aaam            0\n",
       "unmatched_pred_aaam           0\n",
       "exact_icdpic                  0\n",
       "same_reg_same_sev_icdpic      0\n",
       "same_reg_diff_sev_icdpic      0\n",
       "diff_reg_same_sev_icdpic      0\n",
       "diff_reg_diff_sev_icdpic      0\n",
       "unmatched_obs_icdpic          0\n",
       "unmatched_pred_icdpic         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_key</th>\n",
       "      <th>iss_obs</th>\n",
       "      <th>iss_nmt</th>\n",
       "      <th>iss_aaam</th>\n",
       "      <th>iss_icdpic</th>\n",
       "      <th>iss_correct_nmt</th>\n",
       "      <th>iss_correct_aaam</th>\n",
       "      <th>iss_correct_icdpic</th>\n",
       "      <th>iss16_obs</th>\n",
       "      <th>iss16_nmt</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_reg_diff_sev_aaam</th>\n",
       "      <th>unmatched_obs_aaam</th>\n",
       "      <th>unmatched_pred_aaam</th>\n",
       "      <th>exact_icdpic</th>\n",
       "      <th>same_reg_same_sev_icdpic</th>\n",
       "      <th>same_reg_diff_sev_icdpic</th>\n",
       "      <th>diff_reg_same_sev_icdpic</th>\n",
       "      <th>diff_reg_diff_sev_icdpic</th>\n",
       "      <th>unmatched_obs_icdpic</th>\n",
       "      <th>unmatched_pred_icdpic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>190027027754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>190027038612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>190027038739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>190027155991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>190027228272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9668</th>\n",
       "      <td>190045125459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9710</th>\n",
       "      <td>190045281222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819</th>\n",
       "      <td>190045497568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>190045597551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9959</th>\n",
       "      <td>190045621597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           inc_key  iss_obs  iss_nmt  iss_aaam  iss_icdpic  iss_correct_nmt  \\\n",
       "23    190027027754      NaN      NaN        18          41                0   \n",
       "31    190027038612      NaN      9.0         8           6                0   \n",
       "34    190027038739      NaN     14.0        14          14                0   \n",
       "58    190027155991      NaN      NaN        10           8                0   \n",
       "94    190027228272      NaN     10.0         5           2                0   \n",
       "...            ...      ...      ...       ...         ...              ...   \n",
       "9668  190045125459      NaN      NaN         1           4                0   \n",
       "9710  190045281222      NaN      NaN         5           4                0   \n",
       "9819  190045497568      NaN      NaN        43          45                0   \n",
       "9908  190045597551      NaN      NaN         1           6                0   \n",
       "9959  190045621597      NaN      NaN         5           5                0   \n",
       "\n",
       "      iss_correct_aaam  iss_correct_icdpic  iss16_obs  iss16_nmt  ...  \\\n",
       "23                   0                   0          0          0  ...   \n",
       "31                   0                   0          0          0  ...   \n",
       "34                   0                   0          0          0  ...   \n",
       "58                   0                   0          0          0  ...   \n",
       "94                   0                   0          0          0  ...   \n",
       "...                ...                 ...        ...        ...  ...   \n",
       "9668                 0                   0          0          0  ...   \n",
       "9710                 0                   0          0          0  ...   \n",
       "9819                 0                   0          0          0  ...   \n",
       "9908                 0                   0          0          0  ...   \n",
       "9959                 0                   0          0          0  ...   \n",
       "\n",
       "      diff_reg_diff_sev_aaam  unmatched_obs_aaam  unmatched_pred_aaam  \\\n",
       "23                       0.0                 0.0                  0.0   \n",
       "31                       0.0                 0.0                  0.0   \n",
       "34                       0.0                 0.0                  0.0   \n",
       "58                       0.0                 0.0                  0.0   \n",
       "94                       0.0                 0.0                  0.0   \n",
       "...                      ...                 ...                  ...   \n",
       "9668                     1.0                 0.0                  0.0   \n",
       "9710                     0.0                 0.0                  0.0   \n",
       "9819                     1.0                 0.0                  3.0   \n",
       "9908                     0.0                 0.0                  0.0   \n",
       "9959                     1.0                 0.0                  0.0   \n",
       "\n",
       "      exact_icdpic  same_reg_same_sev_icdpic  same_reg_diff_sev_icdpic  \\\n",
       "23             0.0                       1.0                       2.0   \n",
       "31             0.0                       1.0                       1.0   \n",
       "34             0.0                       2.0                       2.0   \n",
       "58             0.0                       0.0                       2.0   \n",
       "94             0.0                       0.0                       0.0   \n",
       "...            ...                       ...                       ...   \n",
       "9668           0.0                       1.0                       1.0   \n",
       "9710           0.0                       1.0                       1.0   \n",
       "9819           0.0                       4.0                       5.0   \n",
       "9908           0.0                       0.0                       1.0   \n",
       "9959           0.0                       0.0                       1.0   \n",
       "\n",
       "      diff_reg_same_sev_icdpic  diff_reg_diff_sev_icdpic  \\\n",
       "23                         1.0                       1.0   \n",
       "31                         0.0                       1.0   \n",
       "34                         2.0                       1.0   \n",
       "58                         2.0                       1.0   \n",
       "94                         0.0                       2.0   \n",
       "...                        ...                       ...   \n",
       "9668                       1.0                       1.0   \n",
       "9710                       0.0                       1.0   \n",
       "9819                      10.0                       1.0   \n",
       "9908                       2.0                       0.0   \n",
       "9959                       3.0                       0.0   \n",
       "\n",
       "      unmatched_obs_icdpic  unmatched_pred_icdpic  \n",
       "23                     0.0                    0.0  \n",
       "31                     0.0                    0.0  \n",
       "34                     0.0                    0.0  \n",
       "58                     0.0                    0.0  \n",
       "94                     0.0                    0.0  \n",
       "...                    ...                    ...  \n",
       "9668                   0.0                    0.0  \n",
       "9710                   0.0                    0.0  \n",
       "9819                   0.0                    4.0  \n",
       "9908                   0.0                    0.0  \n",
       "9959                   0.0                    0.0  \n",
       "\n",
       "[236 rows x 54 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res.iss_obs.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_key</th>\n",
       "      <th>iss_obs</th>\n",
       "      <th>iss_nmt</th>\n",
       "      <th>iss_aaam</th>\n",
       "      <th>iss_icdpic</th>\n",
       "      <th>iss_correct_nmt</th>\n",
       "      <th>iss_correct_aaam</th>\n",
       "      <th>iss_correct_icdpic</th>\n",
       "      <th>iss16_obs</th>\n",
       "      <th>iss16_nmt</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_reg_diff_sev_aaam</th>\n",
       "      <th>unmatched_obs_aaam</th>\n",
       "      <th>unmatched_pred_aaam</th>\n",
       "      <th>exact_icdpic</th>\n",
       "      <th>same_reg_same_sev_icdpic</th>\n",
       "      <th>same_reg_diff_sev_icdpic</th>\n",
       "      <th>diff_reg_same_sev_icdpic</th>\n",
       "      <th>diff_reg_diff_sev_icdpic</th>\n",
       "      <th>unmatched_obs_icdpic</th>\n",
       "      <th>unmatched_pred_icdpic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190026915434</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190026952586</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190026952733</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190026952851</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190026953094</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        inc_key  iss_obs  iss_nmt  iss_aaam  iss_icdpic  iss_correct_nmt  \\\n",
       "0  190026915434      5.0      5.0         5          17                1   \n",
       "1  190026952586      5.0      5.0         5           3                1   \n",
       "2  190026952733      9.0      9.0        25           9                1   \n",
       "3  190026952851      5.0      5.0         5           2                1   \n",
       "4  190026953094      5.0      5.0         5           5                1   \n",
       "\n",
       "   iss_correct_aaam  iss_correct_icdpic  iss16_obs  iss16_nmt  ...  \\\n",
       "0                 1                   0          0          0  ...   \n",
       "1                 1                   0          0          0  ...   \n",
       "2                 0                   1          0          0  ...   \n",
       "3                 1                   0          0          0  ...   \n",
       "4                 1                   1          0          0  ...   \n",
       "\n",
       "   diff_reg_diff_sev_aaam  unmatched_obs_aaam  unmatched_pred_aaam  \\\n",
       "0                     0.0                 0.0                  1.0   \n",
       "1                     0.0                 0.0                  0.0   \n",
       "2                     0.0                 0.0                  0.0   \n",
       "3                     0.0                 0.0                  0.0   \n",
       "4                     0.0                 0.0                  1.0   \n",
       "\n",
       "   exact_icdpic  same_reg_same_sev_icdpic  same_reg_diff_sev_icdpic  \\\n",
       "0           0.0                       1.0                       1.0   \n",
       "1           0.0                       0.0                       1.0   \n",
       "2           0.0                       1.0                       0.0   \n",
       "3           0.0                       0.0                       1.0   \n",
       "4           0.0                       0.0                       0.0   \n",
       "\n",
       "   diff_reg_same_sev_icdpic  diff_reg_diff_sev_icdpic  unmatched_obs_icdpic  \\\n",
       "0                       3.0                       1.0                   0.0   \n",
       "1                       2.0                       0.0                   0.0   \n",
       "2                       0.0                       0.0                   0.0   \n",
       "3                       3.0                       0.0                   0.0   \n",
       "4                       6.0                       0.0                   0.0   \n",
       "\n",
       "   unmatched_pred_icdpic  \n",
       "0                    1.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    1.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
